"use strict";(self.webpackChunkuser_manual=self.webpackChunkuser_manual||[]).push([[3649],{5580:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>r,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"Basics/optimization-loop","title":"Optimization loop","description":"What is the optimization loop?","source":"@site/adk/Basics/optimization-loop.md","sourceDirName":"Basics","slug":"/Basics/optimization-loop","permalink":"/adk/Basics/optimization-loop","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8},"sidebar":"tutorialSidebar","previous":{"title":"Agent Data","permalink":"/adk/Basics/agent-data"},"next":{"title":"Transfer Learning","permalink":"/adk/Basics/transfer-learning"}}');var s=i(4848),o=i(8453);const r={sidebar_position:8},a="Optimization loop",l={},c=[{value:"What is the optimization loop?",id:"what-is-the-optimization-loop",level:2},{value:"Preprocessing in the Optimization Loop",id:"preprocessing-in-the-optimization-loop",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,o.R)(),...n.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(e.header,{children:(0,s.jsx)(e.h1,{id:"optimization-loop",children:"Optimization loop"})}),"\n",(0,s.jsx)(e.h2,{id:"what-is-the-optimization-loop",children:"What is the optimization loop?"}),"\n",(0,s.jsx)(e.p,{children:"The optimization loop is a loop that is continuously run until:"}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsx)(e.li,{children:"An agent is finished learning."}),"\n",(0,s.jsx)(e.li,{children:"A learnt agent is finished optimizing a system."}),"\n",(0,s.jsx)(e.li,{children:'Optimization / training is manually stopped midway through optimization / training with "Stop Optimization".'}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:'The optimization loop is always started with "Start Optimization" on the web interface\'s "Genie"\r\nin a project.'}),"\n",(0,s.jsx)(e.p,{children:"The optimization loop broadly follows the following sequence in the ADK's executor routine:"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["Get the ",(0,s.jsx)(e.strong,{children:"optimization specification"})," from the platform."]}),"\n",(0,s.jsxs)(e.li,{children:["Initialize the ",(0,s.jsx)(e.strong,{children:"agent / environment pair"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["Reset the ",(0,s.jsx)(e.strong,{children:"environment"}),", obtaining an ",(0,s.jsx)(e.code,{children:"observation"})," and some ",(0,s.jsx)(e.code,{children:"info"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["If the ",(0,s.jsx)(e.strong,{children:"optimization specification"})," specifies the agent to run in inference: ",(0,s.jsx)(e.strong,{children:"load the agent models"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["While ",(0,s.jsx)(e.code,{children:"optimizing"}),":","\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsxs)(e.li,{children:["Compute ",(0,s.jsx)(e.code,{children:"action"})," from the ",(0,s.jsx)(e.strong,{children:"agent"})," based on the ",(0,s.jsx)(e.code,{children:"observation"})," and ",(0,s.jsx)(e.code,{children:"info"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["Sample ",(0,s.jsx)(e.code,{children:"env_parameters"})," from the ",(0,s.jsx)(e.strong,{children:"agent"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["Construct ",(0,s.jsx)(e.code,{children:"step_data"})," from the ",(0,s.jsx)(e.code,{children:"action"})," and ",(0,s.jsx)(e.code,{children:"env_parameters"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["Run ",(0,s.jsx)(e.code,{children:"step_data"})," in the ",(0,s.jsx)(e.strong,{children:"environment"}),", obtaining a ",(0,s.jsx)(e.code,{children:"next_observation"}),", ",(0,s.jsx)(e.code,{children:"reward"}),", ",(0,s.jsx)(e.code,{children:"terminated"}),", ",(0,s.jsx)(e.code,{children:"truncated"})," and a ",(0,s.jsx)(e.code,{children:"next_info"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["Add the ",(0,s.jsx)(e.code,{children:"observation"}),", ",(0,s.jsx)(e.code,{children:"action"}),", ",(0,s.jsx)(e.code,{children:"reward"}),", ",(0,s.jsx)(e.code,{children:"next_observation"}),", ",(0,s.jsx)(e.code,{children:"terminated"}),", ",(0,s.jsx)(e.code,{children:"truncated"}),", ",(0,s.jsx)(e.code,{children:"info"})," and ",(0,s.jsx)(e.code,{children:"next_info"}),"\r\nto the agent's experiences."]}),"\n",(0,s.jsxs)(e.li,{children:["Call the agent's ",(0,s.jsx)(e.strong,{children:"learn"})," routine."]}),"\n",(0,s.jsxs)(e.li,{children:["Assign ",(0,s.jsx)(e.code,{children:"next_observation"})," to ",(0,s.jsx)(e.code,{children:"observation"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["Assign ",(0,s.jsx)(e.code,{children:"next_info"})," to ",(0,s.jsx)(e.code,{children:"info"}),"."]}),"\n",(0,s.jsxs)(e.li,{children:["If run in inference and ",(0,s.jsx)(e.code,{children:"terminated"})," is true, stop optimization."]}),"\n",(0,s.jsxs)(e.li,{children:["If ",(0,s.jsx)(e.code,{children:"terminated"})," or ",(0,s.jsx)(e.code,{children:"truncated"}),", reset the ",(0,s.jsx)(e.strong,{children:"environment"}),", obtaining an ",(0,s.jsx)(e.code,{children:"observation"})," and some ",(0,s.jsx)(e.code,{children:"info"}),".\r\nAlso ",(0,s.jsx)(e.strong,{children:"save the agent models"})," if optimization was not run in inference, and the total reward over the\r\nepisode was higher than any of the previous episodes."]}),"\n",(0,s.jsx)(e.li,{children:"Repeat until optimization stops."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.h2,{id:"preprocessing-in-the-optimization-loop",children:"Preprocessing in the Optimization Loop"}),"\n",(0,s.jsxs)(e.p,{children:["Preprocessing happens both ",(0,s.jsx)(e.strong,{children:"at the beginning"})," of optimization and ",(0,s.jsx)(e.strong,{children:"continuously"})," during optimization. The executor integrates preprocessing as follows:"]}),"\n",(0,s.jsxs)(e.ol,{children:["\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Environment reset"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"The initial observation and info are passed through process_env_reset."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"Before agent/environment interaction"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"Agent data is passed through process_agent_data."}),"\n",(0,s.jsx)(e.li,{children:"Specifications are passed through process_specification."}),"\n",(0,s.jsx)(e.li,{children:"Step data is passed through process_agent_step_data."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(e.li,{children:[(0,s.jsx)(e.strong,{children:"After environment step"}),"\n",(0,s.jsxs)(e.ul,{children:["\n",(0,s.jsx)(e.li,{children:"The observation, reward, termination flags, and info are passed through process_env_step."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(e.p,{children:"This ensures that preprocessing is consistently applied whenever the agent interacts with the environment."})]})}function h(n={}){const{wrapper:e}={...(0,o.R)(),...n.components};return e?(0,s.jsx)(e,{...n,children:(0,s.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>r,x:()=>a});var t=i(6540);const s={},o=t.createContext(s);function r(n){const e=t.useContext(o);return t.useMemo((function(){return"function"==typeof n?n(e):{...e,...n}}),[e,n])}function a(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(s):n.components||s:r(n.components),t.createElement(o.Provider,{value:e},n.children)}}}]);